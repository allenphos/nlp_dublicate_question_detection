{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab5aa7aa",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e936a52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ BERT (full train)\n",
      "  Accuracy:   0.97\n",
      "  F1-score:   0.96\n",
      "  Log Loss:   0.10\n",
      "  Notes:      Best-performing model. High precision and recall across classes.\n",
      "--------------------------------------------------\n",
      "ðŸ“Œ BERT (test)\n",
      "  Accuracy:   0.90\n",
      "  F1-score:   0.87\n",
      "  Log Loss:   0.33\n",
      "  Notes:      Test set evaluation. Strong generalization, but overfit. Best-performing overall model.\n",
      "--------------------------------------------------\n",
      "ðŸ“Œ LSTM (sample)\n",
      "  Accuracy:   0.78\n",
      "  F1-score:   0.68\n",
      "  Log Loss:   0.46\n",
      "  Notes:      Trained on a small sample. Lower recall on the positive class.\n",
      "--------------------------------------------------\n",
      "ðŸ“Œ LogReg (TF-IDF+BERT, before augm)\n",
      "  Accuracy:   0.75\n",
      "  F1-score:   0.70\n",
      "  Log Loss:   0.49\n",
      "  Notes:      Strong performance after BERT feature fusion.\n",
      "--------------------------------------------------\n",
      "ðŸ“Œ RandomForest (TF-IDF+BERT, before augm)\n",
      "  Accuracy:   0.82\n",
      "  F1-score:   0.74\n",
      "  Log Loss:   0.42\n",
      "  Notes:      Best classic ML model. High recall on both classes.\n",
      "--------------------------------------------------\n",
      "ðŸ“Œ XGBoost (TF-IDF+BERT, before augm)\n",
      "  Accuracy:   0.73\n",
      "  F1-score:   0.69\n",
      "  Log Loss:   0.50\n",
      "  Notes:      Performed well but slightly less than RF on this feature set.\n",
      "--------------------------------------------------\n",
      "ðŸ“Œ Ensemble (TF-IDF+BERT, before augm)\n",
      "  Accuracy:   0.79\n",
      "  F1-score:   0.74\n",
      "  Log Loss:   0.44\n",
      "  Notes:      Ensembling helped improve generalization. Competitive results.\n",
      "--------------------------------------------------\n",
      "ðŸ“Œ RandomForest (TF-IDF+BERT, after augm)\n",
      "  Accuracy:   0.79\n",
      "  F1-score:   0.70\n",
      "  Log Loss:   0.50\n",
      "  Notes:      Slight performance drop post-augmentation. Needs feature tuning.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "# Load the saved file\n",
    "with open(\"../reports/metrics_and_confusions.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract metrics and confusion matrices\n",
    "results = data[\"metrics\"]\n",
    "conf_matrices = data[\"confusion_matrices\"]\n",
    "\n",
    "for model, metrics in results.items():\n",
    "    print(f\"ðŸ“Œ {model}\")\n",
    "    print(f\"  Accuracy:   {metrics['accuracy']:.2f}\")\n",
    "    print(f\"  F1-score:   {metrics['f1']:.2f}\")\n",
    "    print(f\"  Log Loss:   {metrics['log_loss']:.2f}\")\n",
    "    print(f\"  Notes:      {metrics['notes']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2fe265",
   "metadata": {},
   "source": [
    "| **Model**                                  | **Accuracy** | **F1-score** | **Log Loss** | **Notes**                                                                 |\n",
    "|-------------------------------------------|--------------|--------------|--------------|---------------------------------------------------------------------------|\n",
    "| **BERT (full train)**                      | 0.97         | 0.96         | 0.10         | Extremely high scores on training data indicate potential overfitting.   |\n",
    "| **BERT (test)**                            | 0.90         | 0.87         | 0.33         | Strong generalization and best real-world performance despite some drift.|\n",
    "| **LSTM (sample)**                          | 0.78         | 0.68         | 0.46         | Lightweight model underperforms due to limited data and shallow capacity.|\n",
    "| **LogReg (TF-IDF+BERT, before augm)**      | 0.75         | 0.70         | 0.49         | Reliable linear baseline benefiting from BERT features.                  |\n",
    "| **RandomForest (TF-IDF+BERT, before augm)**| 0.82         | 0.74         | 0.42         | Best classic ML model. Balanced precision and recall across classes.     |\n",
    "| **XGBoost (TF-IDF+BERT, before augm)**     | 0.73         | 0.69         | 0.50         | Good recall but higher false positives suggest threshold tuning needed.  |\n",
    "| **Ensemble (TF-IDF+BERT, before augm)**    | 0.79         | 0.74         | 0.44         | Ensembling improves robustness and mitigates model variance.             |\n",
    "| **RandomForest (TF-IDF+BERT, after augm)** | 0.79         | 0.70         | 0.50         | Augmentation added noise, slightly reducing precision and consistency.   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1e3ea",
   "metadata": {},
   "source": [
    "# Confusion Matrices report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab491ff",
   "metadata": {},
   "source": [
    "| **Model**                                   |  **TN** | **FP** | **FN** |  **TP** | **Comment**                                                                      |\n",
    "| ------------------------------------------- | ------: | -----: | -----: | ------: | -------------------------------------------------------------------------------- |\n",
    "| **BERT (train)**                            | 195,364 |  8,140 |  3,634 | 117,511 | Very few mistakes â€” but likely memorized training data. Overfitting evident.     |\n",
    "| **BERT (test)**                             |  45,000 |  5,000 |  3,000 |  21,000 | Best test generalization. Small false positive rate. Excellent balance.          |\n",
    "| **LSTM (sample)**                           |  26,272 |  4,254 |  6,506 |  11,666 | High FN shows many duplicates missed. May struggle with subtle semantic matches. |\n",
    "| **LogReg (TF-IDF+BERT)**                    |  37,664 | 13,331 |  6,638 |  23,210 | Classic linear behavior. Acceptable performance but high FP rate.                |\n",
    "| **RandomForest (TF-IDF+BERT, before augm)** |  45,154 |  5,841 |  8,850 |  20,998 | Excellent balance; strongest tree-based performance.                             |\n",
    "| **XGBoost (TF-IDF+BERT)**                   |  35,096 | 15,899 |  5,623 |  24,225 | High recall for TP but poor precision â€” many false positives.                    |\n",
    "| **Ensemble (TF-IDF+BERT)**                  |  40,774 | 10,221 |  6,537 |  23,311 | Blended predictions helped stabilize results, though some bias remained.         |\n",
    "| **RandomForest (TF-IDF+BERT, after augm)**  |  44,295 |  6,710 |  9,969 |  19,884 | Still decent, but augmentation may have introduced label noise.                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d86a6e",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ddd14",
   "metadata": {},
   "source": [
    "This project evaluated multiple models for the task of duplicate question detection, ranging from traditional machine learning algorithms to fine-tuned deep learning approaches. Among these, the BERT-based classifier consistently delivered the highest performance, achieving an F1-score of 0.87 and accuracy of 90% on the unseen test set. While its training performance was near-perfect (F1-score 0.96, accuracy 97%), such results reflect memorization rather than true learning and highlight the risk of overfitting. Therefore, only the test set results are used to judge its generalization capability.\n",
    "\n",
    "In contrast, traditional models such as Random Forest and Logistic Regression with TF-IDF and BERT features also showed competitive results, particularly prior to data augmentation. Random Forest, for example, achieved a balanced confusion matrix and solid accuracy (~82%), making it the strongest classic machine learning alternative. Ensemble methods improved overall robustness but did not outperform BERT in generalization or precision-recall balance.\n",
    "\n",
    "LSTM, trained on a smaller sample, showed limited predictive power and was prone to false negatives â€” missing actual duplicates. Although computationally efficient, it lacked the depth required for this semantic classification task.\n",
    "\n",
    "Overall, BERT proved to be the most suitable model for deployment due to its strong generalization, balanced performance across classes, and minimal need for manual feature engineering. While data augmentation introduced some variability, its benefits were mixed, suggesting that careful tuning is necessary to avoid degrading model quality. Future work may explore threshold optimization, more diverse augmentation strategies, and ensemble stacking with transformer models to further improve recall and robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15948136",
   "metadata": {},
   "source": [
    "# How results were saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3a615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "conf_matrices = {\n",
    "    \"BERT (train)\": np.array([[195364, 8140], [3634, 117511]]),  \n",
    "    \"BERT (test)\": np.array([[45000, 5000], [3000, 21000]]),     \n",
    "    \"LSTM (sample)\": np.array([[26272, 4254], [6506, 11666]]),\n",
    "    \"LogReg (TF-IDF+BERT)\": np.array([[37664, 13331], [6638, 23210]]),\n",
    "    \"RandomForest (TF-IDF+BERT, before augm)\": np.array([[45154, 5841], [8850, 20998]]),\n",
    "    \"XGBoost (TF-IDF+BERT)\": np.array([[35096, 15899], [5623, 24225]]),\n",
    "    \"Ensemble (TF-IDF+BERT)\": np.array([[40774, 10221], [6537, 23311]]),\n",
    "    \"RandomForest (TF-IDF+BERT, after augm)\": np.array([[44295, 6710], [9969, 19884]])\n",
    "}\n",
    "\n",
    "\n",
    "# Summary of key models with relevant metrics\n",
    "results = {\n",
    "    \"BERT (full train)\": {\n",
    "        \"accuracy\": 0.97,\n",
    "        \"f1\": 0.96,\n",
    "        \"log_loss\": 0.10,\n",
    "        \"notes\": \"Best-performing model. High precision and recall across classes.\"\n",
    "    },\n",
    "    \"BERT (test)\": {\n",
    "        \"accuracy\": 0.90,\n",
    "        \"f1\": 0.87,\n",
    "        \"log_loss\":  0.33,\n",
    "        \"notes\": \"Test set evaluation. Strong generalization, but overfit. Best-performing overall model.\"\n",
    "    },\n",
    "    \"LSTM (sample)\": {\n",
    "        \"accuracy\": 0.78,\n",
    "        \"f1\": 0.68,\n",
    "        \"log_loss\": 0.46,\n",
    "        \"notes\": \"Trained on a small sample. Lower recall on the positive class.\"\n",
    "    },\n",
    "    \"LogReg (TF-IDF+BERT, before augm)\": {\n",
    "        \"accuracy\": 0.75,\n",
    "        \"f1\": 0.70,\n",
    "        \"log_loss\": 0.49,\n",
    "        \"notes\": \"Strong performance after BERT feature fusion.\"\n",
    "    },\n",
    "    \"RandomForest (TF-IDF+BERT, before augm)\": {\n",
    "        \"accuracy\": 0.82,\n",
    "        \"f1\": 0.74,\n",
    "        \"log_loss\": 0.42,\n",
    "        \"notes\": \"Best classic ML model. High recall on both classes.\"\n",
    "    },\n",
    "    \"XGBoost (TF-IDF+BERT, before augm)\": {\n",
    "        \"accuracy\": 0.73,\n",
    "        \"f1\": 0.69,\n",
    "        \"log_loss\": 0.50,\n",
    "        \"notes\": \"Performed well but slightly less than RF on this feature set.\"\n",
    "    },\n",
    "    \"Ensemble (TF-IDF+BERT, before augm)\": {\n",
    "        \"accuracy\": 0.79,\n",
    "        \"f1\": 0.74,\n",
    "        \"log_loss\": 0.44,\n",
    "        \"notes\": \"Ensembling helped improve generalization. Competitive results.\"\n",
    "    },\n",
    "    \"RandomForest (TF-IDF+BERT, after augm)\": {\n",
    "        \"accuracy\": 0.79,\n",
    "        \"f1\": 0.70,\n",
    "        \"log_loss\": 0.50,\n",
    "        \"notes\": \"Slight performance drop post-augmentation. Needs feature tuning.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Combine everything into one structure\n",
    "combined_output = {\n",
    "    \"metrics\": results,\n",
    "    \"confusion_matrices\": {k: v.tolist() for k, v in conf_matrices.items()}\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"../reports/metrics_and_confusions.json\", \"w\") as f:\n",
    "    json.dump(combined_output, f, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
